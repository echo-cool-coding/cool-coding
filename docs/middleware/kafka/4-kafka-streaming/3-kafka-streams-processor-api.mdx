---
title: Kafka Streams 处理器 API
description: 了解 Kafka Streams 处理器 API 的基础知识，掌握如何使用它构建自定义流处理逻辑。
---

# Kafka Streams 处理器 API

Kafka Streams 是 Apache Kafka 提供的一个强大的流处理库，允许开发者以声明式的方式处理实时数据流。Kafka Streams 提供了两种主要的 API：**DSL（领域特定语言）** 和 **处理器 API（Processor API）**。本文将重点介绍 **处理器 API**，它提供了更底层的控制，适合需要自定义处理逻辑的场景。

## 什么是 Kafka Streams 处理器 API？

Kafka Streams 处理器 API 是一个低级别的 API，允许开发者直接操作 Kafka 流中的每条记录。与 DSL 相比，处理器 API 提供了更高的灵活性，允许你定义自定义的处理逻辑、状态存储和拓扑结构。它适用于需要精细控制流处理逻辑的场景。

### 核心概念

1. **Processor**：处理器是 Kafka Streams 中的基本处理单元。每个处理器负责处理输入记录，并可能生成输出记录。
2. **ProcessorContext**：处理器上下文提供了处理器的运行时环境，允许处理器访问状态存储、调度定时器等。
3. **Topology**：拓扑是 Kafka Streams 应用程序的处理逻辑图。它由多个处理器节点和它们之间的连接组成。

## 如何使用 Kafka Streams 处理器 API

### 1. 创建拓扑

首先，你需要定义一个拓扑（Topology），它描述了数据流的处理逻辑。以下是一个简单的拓扑示例：

```java
Topology topology = new Topology();

// 添加源处理器
topology.addSource("Source", "input-topic");

// 添加自定义处理器
topology.addProcessor("Processor", () -> new MyProcessor(), "Source");

// 添加目标处理器
topology.addSink("Sink", "output-topic", "Processor");
```

在这个示例中，`MyProcessor` 是一个自定义的处理器类，它实现了 `Processor` 接口。

### 2. 实现自定义处理器

接下来，你需要实现一个自定义处理器。以下是一个简单的处理器示例：

```java
public class MyProcessor implements Processor<String, String> {
    private ProcessorContext context;

    @Override
    public void init(ProcessorContext context) {
        this.context = context;
    }

    @Override
    public void process(String key, String value) {
        // 处理输入记录
        String transformedValue = value.toUpperCase();

        // 发送处理后的记录到下游
        context.forward(key, transformedValue);
    }

    @Override
    public void close() {
        // 清理资源
    }
}
```

在这个示例中，`MyProcessor` 将输入记录的值转换为大写，并将其发送到下游。

### 3. 运行 Kafka Streams 应用程序

最后，你需要创建一个 Kafka Streams 实例并启动它：

```java
KafkaStreams streams = new KafkaStreams(topology, props);
streams.start();
```

## 实际应用场景

### 场景：实时日志处理

假设你有一个日志流，每条日志记录包含一个消息。你希望实时处理这些日志，将消息转换为大写，并将处理后的日志存储到另一个 Kafka 主题中。

```java
Topology topology = new Topology();

// 添加源处理器
topology.addSource("Source", "logs-topic");

// 添加自定义处理器
topology.addProcessor("Processor", () -> new LogProcessor(), "Source");

// 添加目标处理器
topology.addSink("Sink", "processed-logs-topic", "Processor");

KafkaStreams streams = new KafkaStreams(topology, props);
streams.start();
```

在这个场景中，`LogProcessor` 是一个自定义处理器，它将日志消息转换为大写。

## 总结

Kafka Streams 处理器 API 提供了强大的灵活性，允许开发者构建自定义的流处理逻辑。通过定义拓扑和实现自定义处理器，你可以处理复杂的实时数据流。虽然处理器 API 比 DSL 更底层，但它为需要精细控制的场景提供了极大的便利。

### 附加资源

- [Kafka Streams 官方文档](https://kafka.apache.org/documentation/streams/)
- [Kafka Streams 处理器 API 示例](https://github.com/apache/kafka/tree/trunk/streams/examples/src/main/java/org/apache/kafka/streams/examples/processor)

### 练习

1. 尝试实现一个自定义处理器，将输入记录的值转换为小写。
2. 修改拓扑，添加多个处理器节点，并观察数据流的变化。
