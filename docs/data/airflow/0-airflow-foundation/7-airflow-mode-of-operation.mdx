---
title: Airflow 运行模式
description: 了解 Airflow 的运行模式，包括本地模式、Celery 模式和 Kubernetes 模式，以及它们的使用场景和配置方法。
---

# Airflow 运行模式

Apache Airflow 是一个用于编排、调度和监控工作流的强大工具。为了满足不同的需求，Airflow 提供了多种运行模式。本文将详细介绍 Airflow 的几种主要运行模式，包括本地模式、Celery 模式和 Kubernetes 模式，并探讨它们的使用场景和配置方法。

## 1. 本地模式（LocalExecutor）

本地模式是 Airflow 最简单的运行模式，适用于开发和测试环境。在本地模式下，所有任务都在同一台机器上执行，使用本地进程来并行处理任务。

### 配置方法

要启用本地模式，只需在 `airflow.cfg` 文件中将 `executor` 设置为 `LocalExecutor`：

```ini
executor = LocalExecutor
```

### 使用场景

- **开发和测试**：本地模式非常适合在开发环境中快速测试和调试 DAG。
- **单机部署**：如果你的工作流规模较小，且不需要分布式执行任务，本地模式是一个不错的选择。

:::tip
本地模式的优点是配置简单，但它的并行处理能力受限于本地机器的资源。
:::

## 2. Celery 模式（CeleryExecutor）

Celery 模式是 Airflow 的分布式运行模式，适用于生产环境。它使用 Celery 作为任务队列，允许多个 worker 节点并行执行任务。

### 配置方法

要启用 Celery 模式，需要在 `airflow.cfg` 文件中将 `executor` 设置为 `CeleryExecutor`，并配置 Celery 的后端（如 Redis 或 RabbitMQ）：

```ini
executor = CeleryExecutor
broker_url = redis://localhost:6379/0
result_backend = redis://localhost:6379/0
```

### 使用场景

- **生产环境**：Celery 模式适合在生产环境中运行大规模的工作流。
- **分布式任务执行**：如果你的任务需要跨多个节点执行，Celery 模式是理想的选择。

:::caution
Celery 模式的配置相对复杂，需要额外设置消息队列和后端存储。
:::

## 3. Kubernetes 模式（KubernetesExecutor）

Kubernetes 模式是 Airflow 的另一种分布式运行模式，专为 Kubernetes 集群设计。它允许每个任务在独立的 Kubernetes Pod 中运行，提供了更高的资源隔离性和弹性。

### 配置方法

要启用 Kubernetes 模式，需要在 `airflow.cfg` 文件中将 `executor` 设置为 `KubernetesExecutor`，并配置 Kubernetes 集群的相关参数：

```ini
executor = KubernetesExecutor
```

### 使用场景

- **容器化环境**：如果你的基础设施基于 Kubernetes，Kubernetes 模式是最佳选择。
- **高资源隔离性**：每个任务在独立的 Pod 中运行，确保了任务之间的资源隔离。

:::warning
Kubernetes 模式的配置和管理较为复杂，需要对 Kubernetes 有一定的了解。
:::

## 实际案例

### 案例 1：本地模式下的简单 DAG

以下是一个在本地模式下运行的简单 DAG 示例：

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

dag = DAG(
    'example_dag',
    start_date=datetime(2023, 1, 1),
    schedule_interval='@daily',
)

task1 = BashOperator(
    task_id='print_date',
    bash_command='date',
    dag=dag,
)

task2 = BashOperator(
    task_id='sleep',
    bash_command='sleep 5',
    dag=dag,
)

task1 >> task2
```

在这个例子中，`task1` 和 `task2` 将在本地模式下顺序执行。

### 案例 2：Celery 模式下的分布式任务

在 Celery 模式下，你可以将任务分发到多个 worker 节点上执行。以下是一个简单的 DAG 示例：

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

dag = DAG(
    'distributed_dag',
    start_date=datetime(2023, 1, 1),
    schedule_interval='@daily',
)

task1 = BashOperator(
    task_id='task1',
    bash_command='echo "Running on worker 1"',
    dag=dag,
)

task2 = BashOperator(
    task_id='task2',
    bash_command='echo "Running on worker 2"',
    dag=dag,
)

task1 >> task2
```

在这个例子中，`task1` 和 `task2` 可能会在不同的 worker 节点上执行。

## 总结

Airflow 提供了多种运行模式，以满足不同的需求。本地模式适合开发和测试，Celery 模式适合生产环境中的分布式任务执行，而 Kubernetes 模式则适合容器化环境和高资源隔离性需求。

选择合适的运行模式取决于你的具体需求和基础设施。希望本文能帮助你更好地理解 Airflow 的运行模式，并为你的工作流选择合适的配置。

## 附加资源

- [Airflow 官方文档](https://airflow.apache.org/docs/)
- [Celery 官方文档](https://docs.celeryproject.org/en/stable/)
- [Kubernetes 官方文档](https://kubernetes.io/docs/)

## 练习

1. 在本地模式下创建一个简单的 DAG，并观察任务的执行顺序。
2. 尝试在 Celery 模式下配置 Airflow，并运行一个分布式任务。
3. 如果你有 Kubernetes 集群，尝试配置 Kubernetes 模式并运行一个任务。

通过实践，你将更深入地理解 Airflow 的不同运行模式及其适用场景。