---
title: Airflow 调度策略
description: 了解Airflow中的调度策略，掌握如何配置和管理任务的调度与触发。
---

# Airflow 调度策略

Airflow 是一个强大的工作流调度工具，广泛用于数据管道的编排和管理。调度策略是 Airflow 的核心功能之一，它决定了任务何时以及如何被触发和执行。本文将详细介绍 Airflow 的调度策略，帮助初学者理解并掌握这一重要概念。

## 什么是调度策略？

调度策略是指 Airflow 如何根据时间或其他条件来决定任务的执行时间。Airflow 的调度器（Scheduler）负责监控任务的调度时间，并在满足条件时触发任务的执行。调度策略的配置直接影响任务的执行频率、时间点以及依赖关系。

## 基本调度配置

在 Airflow 中，任务的调度主要通过 DAG（有向无环图）的 `schedule_interval` 参数来配置。`schedule_interval` 可以是一个时间间隔（如 `@daily`、`@hourly`），也可以是一个 CRON 表达式（如 `0 0 * * *`）。

### 示例：配置每日任务

以下是一个简单的 DAG 配置示例，该 DAG 每天执行一次：

```python
from airflow import DAG
from airflow.operators.dummy_operator import DummyOperator
from datetime import datetime

dag = DAG(
    'daily_task',
    description='一个每天执行的任务',
    schedule_interval='@daily',
    start_date=datetime(2023, 1, 1),
    catchup=False
)

task = DummyOperator(
    task_id='daily_task',
    dag=dag
)
```

在这个示例中，`schedule_interval='@daily'` 表示该 DAG 每天执行一次。`start_date` 定义了 DAG 的开始日期，`catchup=False` 表示不进行历史任务的补跑。

## 调度策略的详细解析

### 1. CRON 表达式

CRON 表达式是一种常用的调度配置方式，它允许你精确地定义任务的执行时间。Airflow 支持标准的 CRON 表达式语法。

#### 示例：使用 CRON 表达式

```python
dag = DAG(
    'cron_scheduled_task',
    description='使用 CRON 表达式调度的任务',
    schedule_interval='0 0 * * *',  # 每天午夜执行
    start_date=datetime(2023, 1, 1),
    catchup=False
)
```

在这个示例中，`schedule_interval='0 0 * * *'` 表示任务将在每天的午夜（00:00）执行。

### 2. 时间间隔

除了 CRON 表达式，Airflow 还支持一些预定义的时间间隔，如 `@daily`、`@hourly`、`@weekly` 等。这些时间间隔可以简化调度配置。

#### 示例：使用预定义时间间隔

```python
dag = DAG(
    'hourly_task',
    description='每小时执行的任务',
    schedule_interval='@hourly',
    start_date=datetime(2023, 1, 1),
    catchup=False
)
```

在这个示例中，`schedule_interval='@hourly'` 表示任务将每小时执行一次。

### 3. 调度与依赖关系

Airflow 的调度策略还涉及到任务之间的依赖关系。任务可以依赖于其他任务的完成情况，Airflow 会根据这些依赖关系来决定任务的执行顺序。

#### 示例：任务依赖关系

```python
task1 = DummyOperator(
    task_id='task1',
    dag=dag
)

task2 = DummyOperator(
    task_id='task2',
    dag=dag
)

task1 >> task2  # task2 依赖于 task1 的完成
```

在这个示例中，`task2` 将在 `task1` 完成后执行。

## 实际应用场景

### 场景：数据管道调度

假设你有一个数据管道，需要每天从数据库中提取数据，进行转换，然后加载到数据仓库中。你可以使用 Airflow 来调度这个管道，确保每个步骤按时执行。

```python
from airflow.operators.python_operator import PythonOperator

def extract_data():
    print("Extracting data...")

def transform_data():
    print("Transforming data...")

def load_data():
    print("Loading data...")

dag = DAG(
    'data_pipeline',
    description='一个简单的数据管道',
    schedule_interval='@daily',
    start_date=datetime(2023, 1, 1),
    catchup=False
)

extract_task = PythonOperator(
    task_id='extract_data',
    python_callable=extract_data,
    dag=dag
)

transform_task = PythonOperator(
    task_id='transform_data',
    python_callable=transform_data,
    dag=dag
)

load_task = PythonOperator(
    task_id='load_data',
    python_callable=load_data,
    dag=dag
)

extract_task >> transform_task >> load_task
```

在这个场景中，`extract_task`、`transform_task` 和 `load_task` 将按顺序执行，确保数据管道的每个步骤都按时完成。

## 总结

Airflow 的调度策略是任务调度的核心，通过合理配置 `schedule_interval` 和任务依赖关系，你可以精确控制任务的执行时间和顺序。本文介绍了基本的调度配置、CRON 表达式、时间间隔以及任务依赖关系，并通过实际应用场景展示了如何在实际项目中使用这些策略。

## 附加资源与练习

- **官方文档**: [Airflow 调度器文档](https://airflow.apache.org/docs/apache-airflow/stable/scheduler.html)
- **练习**: 尝试创建一个每小时执行的 DAG，并配置任务之间的依赖关系。
- **进一步学习**: 了解 Airflow 的 `catchup` 参数及其对调度的影响。

通过不断实践和探索，你将能够更好地掌握 Airflow 的调度策略，并在实际项目中灵活运用。