---
title: HDFS文件上传下载
description: 学习如何在HDFS（Hadoop分布式文件系统）中上传和下载文件。本文适合初学者，包含详细的步骤、代码示例和实际应用场景。
---

# HDFS文件上传下载

HDFS（Hadoop分布式文件系统）是Hadoop生态系统的核心组件之一，用于存储和管理大规模数据集。HDFS的设计目标是支持高吞吐量的数据访问，适合处理大数据应用场景。本文将详细介绍如何在HDFS中上传和下载文件，帮助初学者快速掌握这一基本操作。

## 1. HDFS文件系统简介

HDFS是一个分布式文件系统，它将大文件分割成多个块（默认大小为128MB或256MB），并将这些块存储在不同的节点上。HDFS具有高容错性，能够自动处理节点故障，并支持数据的并行处理。

## 2. HDFS文件上传

### 2.1 使用HDFS命令行工具上传文件

HDFS提供了一个命令行工具 `hdfs dfs`，可以用来与HDFS进行交互。以下是将本地文件上传到HDFS的基本命令：

```bash
hdfs dfs -put <本地文件路径> <HDFS目标路径>
```

**示例：**

假设我们有一个本地文件 `example.txt`，我们希望将其上传到HDFS的 `/user/hadoop/input` 目录下：

```bash
hdfs dfs -put /path/to/local/example.txt /user/hadoop/input
```

**输出：**

如果上传成功，命令行不会有任何输出。你可以使用以下命令来确认文件是否已上传：

```bash
hdfs dfs -ls /user/hadoop/input
```

**输出示例：**

```
Found 1 items
-rw-r--r--   1 hadoop supergroup         52 2023-10-01 12:34 /user/hadoop/input/example.txt
```

### 2.2 使用Java API上传文件

除了命令行工具，你还可以使用Hadoop的Java API来上传文件。以下是一个简单的Java代码示例：

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.IOException;

public class HDFSUpload {
    public static void main(String[] args) {
        String localFilePath = "/path/to/local/example.txt";
        String hdfsFilePath = "/user/hadoop/input/example.txt";

        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", "hdfs://localhost:9000");

        try (FileSystem fs = FileSystem.get(conf)) {
            fs.copyFromLocalFile(new Path(localFilePath), new Path(hdfsFilePath));
            System.out.println("文件上传成功！");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

**运行结果：**

如果代码运行成功，控制台将输出 `文件上传成功！`。

## 3. HDFS文件下载

### 3.1 使用HDFS命令行工具下载文件

与上传文件类似，HDFS也提供了命令行工具来下载文件。以下是下载HDFS文件到本地的基本命令：

```bash
hdfs dfs -get <HDFS文件路径> <本地目标路径>
```

**示例：**

假设我们希望将HDFS中的 `/user/hadoop/input/example.txt` 文件下载到本地的 `/path/to/local/` 目录下：

```bash
hdfs dfs -get /user/hadoop/input/example.txt /path/to/local/
```

**输出：**

如果下载成功，命令行不会有任何输出。你可以在本地目录中查看下载的文件。

### 3.2 使用Java API下载文件

同样地，你也可以使用Hadoop的Java API来下载文件。以下是一个简单的Java代码示例：

```java
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import java.io.IOException;

public class HDFSDownload {
    public static void main(String[] args) {
        String hdfsFilePath = "/user/hadoop/input/example.txt";
        String localFilePath = "/path/to/local/example.txt";

        Configuration conf = new Configuration();
        conf.set("fs.defaultFS", "hdfs://localhost:9000");

        try (FileSystem fs = FileSystem.get(conf)) {
            fs.copyToLocalFile(new Path(hdfsFilePath), new Path(localFilePath));
            System.out.println("文件下载成功！");
        } catch (IOException e) {
            e.printStackTrace();
        }
    }
}
```

**运行结果：**

如果代码运行成功，控制台将输出 `文件下载成功！`。

## 4. 实际应用场景

### 4.1 大数据处理中的数据准备

在大数据处理中，通常需要将原始数据上传到HDFS中，以便后续的MapReduce或Spark作业进行处理。例如，一个电商公司可能需要将用户行为日志上传到HDFS，以便分析用户行为模式。

### 4.2 数据备份与恢复

HDFS的高容错性使其成为数据备份的理想选择。企业可以将重要数据上传到HDFS中，以防止数据丢失。在需要时，可以从HDFS中下载数据以进行恢复。

## 5. 总结

本文介绍了如何在HDFS中上传和下载文件，涵盖了命令行工具和Java API的使用方法。通过这些操作，你可以轻松地将数据存储到HDFS中，并在需要时将其下载到本地。HDFS是大数据处理的基础，掌握这些基本操作对于进一步学习Hadoop生态系统至关重要。

## 6. 附加资源与练习

- **练习1**：尝试使用命令行工具将多个文件上传到HDFS，并使用 `hdfs dfs -ls` 命令查看上传结果。
- **练习2**：编写一个Java程序，将HDFS中的多个文件下载到本地，并统计文件的总大小。
- **附加资源**：
  - [Hadoop官方文档](https://hadoop.apache.org/docs/stable/)
  - 《Hadoop权威指南》—— Tom White

:::tip
如果你在学习过程中遇到问题，可以访问Hadoop社区论坛或Stack Overflow寻求帮助。
:::