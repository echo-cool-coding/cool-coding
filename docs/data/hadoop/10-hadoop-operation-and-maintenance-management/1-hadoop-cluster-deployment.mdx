---
title: Hadoop 集群部署
description: 本教程将详细介绍如何部署Hadoop集群，适合初学者学习Hadoop运维管理的基础知识。
---

# Hadoop 集群部署

Hadoop是一个开源的分布式计算框架，广泛用于大数据处理。Hadoop集群部署是Hadoop运维管理中的核心任务之一，它涉及在多台服务器上配置和启动Hadoop的各个组件，以实现分布式存储和计算。

## 1. 概述

Hadoop集群通常由以下几个核心组件组成：

- **HDFS（Hadoop Distributed File System）**：分布式文件系统，用于存储大规模数据。
- **YARN（Yet Another Resource Negotiator）**：资源管理框架，负责集群资源的调度和管理。
- **MapReduce**：分布式计算框架，用于处理大规模数据集。

在部署Hadoop集群时，我们需要在多个节点上安装和配置这些组件，并确保它们能够协同工作。

## 2. 部署前的准备

在开始部署之前，确保你已经完成了以下准备工作：

1. **硬件准备**：至少准备三台服务器（可以是虚拟机），分别作为NameNode、ResourceManager和DataNode/NodeManager。
2. **操作系统**：确保所有节点都安装了相同的操作系统（推荐使用Linux，如CentOS或Ubuntu）。
3. **网络配置**：确保所有节点之间可以通过SSH无密码访问。
4. **Java环境**：Hadoop依赖于Java，确保所有节点都安装了Java 8或更高版本。

## 3. 安装和配置Hadoop

### 3.1 下载和解压Hadoop

首先，在所有节点上下载Hadoop并解压：

```bash
wget https://downloads.apache.org/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz
tar -xzvf hadoop-3.3.1.tar.gz
mv hadoop-3.3.1 /usr/local/hadoop
```

### 3.2 配置环境变量

在所有节点上配置Hadoop的环境变量。编辑 `~/.bashrc` 文件，添加以下内容：

```bash
export HADOOP_HOME=/usr/local/hadoop
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

然后执行 `source ~/.bashrc` 使配置生效。

### 3.3 配置Hadoop核心文件

在 `$HADOOP_HOME/etc/hadoop/` 目录下，编辑以下配置文件：

#### 3.3.1 `core-site.xml`

```xml
<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://namenode:9000</value>
    </property>
</configuration>
```

#### 3.3.2 `hdfs-site.xml`

```xml
<configuration>
    <property>
        <name>dfs.replication</name>
        <value>3</value>
    </property>
    <property>
        <name>dfs.namenode.name.dir</name>
        <value>/usr/local/hadoop/data/namenode</value>
    </property>
    <property>
        <name>dfs.datanode.data.dir</name>
        <value>/usr/local/hadoop/data/datanode</value>
    </property>
</configuration>
```

#### 3.3.3 `yarn-site.xml`

```xml
<configuration>
    <property>
        <name>yarn.nodemanager.aux-services</name>
        <value>mapreduce_shuffle</value>
    </property>
    <property>
        <name>yarn.resourcemanager.hostname</name>
        <value>resourcemanager</value>
    </property>
</configuration>
```

#### 3.3.4 `mapred-site.xml`

```xml
<configuration>
    <property>
        <name>mapreduce.framework.name</name>
        <value>yarn</value>
    </property>
</configuration>
```

### 3.4 配置主从节点

在 `$HADOOP_HOME/etc/hadoop/workers` 文件中，列出所有DataNode的主机名：

```
datanode1
datanode2
datanode3
```

在 `$HADOOP_HOME/etc/hadoop/masters` 文件中，列出NameNode和ResourceManager的主机名：

```
namenode
resourcemanager
```

### 3.5 启动Hadoop集群

在所有节点上完成配置后，可以启动Hadoop集群：

1. **格式化HDFS**：在NameNode上执行以下命令：

    ```bash
    hdfs namenode -format
    ```

2. **启动HDFS**：在NameNode上执行以下命令：

    ```bash
    start-dfs.sh
    ```

3. **启动YARN**：在ResourceManager上执行以下命令：

    ```bash
    start-yarn.sh
    ```

4. **验证集群状态**：在浏览器中访问 `http://namenode:9870` 查看HDFS状态，访问 `http://resourcemanager:8088` 查看YARN状态。

## 4. 实际案例

假设我们有一个包含三台服务器的集群，主机名分别为 `namenode`、`datanode1` 和 `datanode2`。我们按照上述步骤配置并启动Hadoop集群后，可以通过以下命令验证集群是否正常工作：

```bash
hdfs dfs -mkdir /test
hdfs dfs -put /path/to/local/file /test
hdfs dfs -ls /test
```

如果一切正常，你应该能够看到上传的文件列表。

## 5. 总结

通过本教程，你已经学会了如何部署一个基本的Hadoop集群。Hadoop集群部署是Hadoop运维管理的基础，掌握这一技能对于进一步学习和使用Hadoop至关重要。

## 6. 附加资源

- [Hadoop官方文档](https://hadoop.apache.org/docs/stable/)
- [Hadoop集群管理指南](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html)
- [Hadoop YARN配置指南](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/YARN.html)

## 7. 练习

1. 尝试在一个四节点的集群上部署Hadoop，并验证其功能。
2. 修改HDFS的副本因子为2，观察集群行为的变化。
3. 研究如何配置Hadoop的高可用性（HA）模式。

:::tip
在部署过程中遇到问题时，可以查看Hadoop的日志文件，通常位于 `$HADOOP_HOME/logs/` 目录下。
:::