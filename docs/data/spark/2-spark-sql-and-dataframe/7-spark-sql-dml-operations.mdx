---
title: Spark SQL DML操作
description: 了解如何使用Spark SQL的DML（数据操作语言）操作DataFrame，包括插入、更新、删除和合并数据。
---

# Spark SQL DML操作

在Spark SQL中，DML（数据操作语言）操作用于对数据进行插入、更新、删除和合并等操作。这些操作是数据处理和分析的核心部分，尤其是在处理大规模数据集时。本文将详细介绍如何在Spark SQL中使用DML操作，并通过实际案例帮助初学者理解这些操作的应用场景。

## 什么是DML操作？

DML（Data Manipulation Language）是SQL语言的一部分，用于操作数据库中的数据。常见的DML操作包括：

- **INSERT**：向表中插入新数据。
- **UPDATE**：更新表中的现有数据。
- **DELETE**：从表中删除数据。
- **MERGE**：将源表中的数据合并到目标表中。

在Spark SQL中，这些操作可以通过DataFrame API或SQL语句来实现。

## 插入数据（INSERT）

插入操作用于向表中添加新数据。在Spark SQL中，可以通过`INSERT INTO`语句或DataFrame API的`write.insertInto()`方法来实现。

### 使用SQL语句插入数据

假设我们有一个名为`employees`的表，结构如下：

```sql
CREATE TABLE employees (
    id INT,
    name STRING,
    salary DOUBLE
);
```

我们可以使用以下SQL语句向表中插入一条新记录：

```sql
INSERT INTO employees VALUES (1, 'Alice', 50000.0);
```

### 使用DataFrame API插入数据

如果你有一个DataFrame，可以使用`write.insertInto()`方法将数据插入到表中：

```python
data = [(2, 'Bob', 60000.0)]
columns = ["id", "name", "salary"]
df = spark.createDataFrame(data, columns)
df.write.insertInto("employees")
```

## 更新数据（UPDATE）

更新操作用于修改表中的现有数据。在Spark SQL中，更新操作通常通过SQL语句来实现。

### 使用SQL语句更新数据

假设我们想将`employees`表中`id`为1的员工的薪水更新为55000.0，可以使用以下SQL语句：

```sql
UPDATE employees SET salary = 55000.0 WHERE id = 1;
```

:::note
Spark SQL目前不支持直接通过DataFrame API进行更新操作。更新操作通常通过SQL语句或重新创建DataFrame来实现。
:::

## 删除数据（DELETE）

删除操作用于从表中移除数据。在Spark SQL中，删除操作通常通过SQL语句来实现。

### 使用SQL语句删除数据

假设我们想从`employees`表中删除`id`为2的员工记录，可以使用以下SQL语句：

```sql
DELETE FROM employees WHERE id = 2;
```

:::caution
删除操作是不可逆的，请谨慎使用。
:::

## 合并数据（MERGE）

合并操作用于将源表中的数据合并到目标表中。如果目标表中已存在匹配的记录，则更新该记录；否则，插入新记录。

### 使用SQL语句合并数据

假设我们有两个表：`employees`和`new_employees`，我们想将`new_employees`中的数据合并到`employees`中。可以使用以下SQL语句：

```sql
MERGE INTO employees AS target
USING new_employees AS source
ON target.id = source.id
WHEN MATCHED THEN
    UPDATE SET target.name = source.name, target.salary = source.salary
WHEN NOT MATCHED THEN
    INSERT (id, name, salary) VALUES (source.id, source.name, source.salary);
```

## 实际案例

假设我们有一个电商平台的订单表`orders`，结构如下：

```sql
CREATE TABLE orders (
    order_id INT,
    customer_id INT,
    order_date DATE,
    total_amount DOUBLE
);
```

我们需要定期从新订单表`new_orders`中合并数据到`orders`表中。可以使用以下SQL语句：

```sql
MERGE INTO orders AS target
USING new_orders AS source
ON target.order_id = source.order_id
WHEN MATCHED THEN
    UPDATE SET target.customer_id = source.customer_id, target.order_date = source.order_date, target.total_amount = source.total_amount
WHEN NOT MATCHED THEN
    INSERT (order_id, customer_id, order_date, total_amount) VALUES (source.order_id, source.customer_id, source.order_date, source.total_amount);
```

## 总结

本文介绍了Spark SQL中的DML操作，包括插入、更新、删除和合并数据。通过这些操作，你可以有效地管理和操作大规模数据集。虽然Spark SQL的DataFrame API在某些操作上有限制，但通过SQL语句，你可以实现更复杂的数据操作。

## 附加资源与练习

- **练习1**：创建一个包含学生信息的表`students`，并尝试使用DML操作插入、更新和删除数据。
- **练习2**：使用`MERGE`语句将两个包含产品信息的表合并，并确保重复数据被正确更新。

通过这些练习，你将更好地掌握Spark SQL中的DML操作，并能够在实际项目中灵活运用。