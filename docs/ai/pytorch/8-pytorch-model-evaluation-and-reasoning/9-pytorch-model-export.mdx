---
title: PyTorch 模型导出
description: 学习如何将训练好的PyTorch模型导出为可用于推理的格式，并了解其在实际应用中的重要性。
---

# PyTorch 模型导出

在深度学习中，模型训练完成后，通常需要将其导出以便在生产环境中进行推理。PyTorch提供了多种导出模型的方式，本文将详细介绍这些方法，并通过实际案例帮助你理解如何将模型导出并应用于实际场景。

## 什么是模型导出？

模型导出是指将训练好的模型保存为特定格式，以便在其他环境中加载和使用。导出的模型通常不包含训练过程中的优化器和损失函数，而是专注于推理任务。PyTorch提供了多种导出模型的方式，包括保存整个模型、仅保存模型参数、以及将模型导出为ONNX格式等。

## 导出模型的常见方法

### 1. 保存整个模型

最简单的方法是使用 `torch.save` 保存整个模型。这种方法会将模型的结构和参数一起保存，方便在相同环境中加载和使用。

```python
import torch
import torch.nn as nn

# 定义一个简单的模型
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(10, 1)

    def forward(self, x):
        return self.fc(x)

# 实例化模型并训练
model = SimpleModel()
# 假设模型已经训练完成

# 保存整个模型
torch.save(model, 'model.pth')
```

:::note
保存整个模型时，模型的类定义必须在加载时可用。这意味着如果你在另一个脚本中加载模型，必须确保模型类的定义与保存时一致。
:::

### 2. 仅保存模型参数

另一种常见的方法是仅保存模型的参数（state_dict），而不保存模型的结构。这种方法更加灵活，因为你可以根据需要重新定义模型结构。

```python
# 仅保存模型参数
torch.save(model.state_dict(), 'model_params.pth')

# 加载模型参数
model = SimpleModel()
model.load_state_dict(torch.load('model_params.pth'))
```

:::tip
仅保存模型参数可以减小文件大小，并且在加载时可以灵活地调整模型结构。
:::

### 3. 导出为ONNX格式

ONNX（Open Neural Network Exchange）是一种开放的模型格式，支持跨平台和跨框架的模型部署。PyTorch提供了 `torch.onnx.export` 函数，可以将模型导出为ONNX格式。

```python
import torch.onnx

# 定义一个输入张量
dummy_input = torch.randn(1, 10)

# 导出模型为ONNX格式
torch.onnx.export(model, dummy_input, 'model.onnx', input_names=['input'], output_names=['output'])
```

:::caution
导出为ONNX格式时，需要确保模型的输入和输出与目标框架兼容。某些PyTorch操作可能不被ONNX支持，因此在导出时可能会遇到问题。
:::

## 实际应用案例

假设你正在开发一个图像分类应用，训练了一个卷积神经网络（CNN）模型。为了在生产环境中使用该模型，你需要将其导出为ONNX格式，并在一个支持ONNX的推理引擎中加载和运行。

```python
import torch
import torch.nn as nn
import torch.onnx

# 定义一个简单的CNN模型
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)
        self.fc = nn.Linear(32 * 28 * 28, 10)

    def forward(self, x):
        x = self.conv1(x)
        x = x.view(x.size(0), -1)
        x = self.fc(x)
        return x

# 实例化模型并训练
model = SimpleCNN()
# 假设模型已经训练完成

# 导出模型为ONNX格式
dummy_input = torch.randn(1, 1, 28, 28)
torch.onnx.export(model, dummy_input, 'cnn_model.onnx', input_names=['input'], output_names=['output'])
```

在这个案例中，我们将一个简单的CNN模型导出为ONNX格式，以便在支持ONNX的推理引擎中使用。

## 总结

PyTorch提供了多种导出模型的方式，包括保存整个模型、仅保存模型参数、以及导出为ONNX格式。每种方法都有其适用的场景和注意事项。在实际应用中，选择合适的导出方法可以大大提高模型的部署效率。

## 附加资源与练习

- **练习**：尝试将一个简单的线性回归模型导出为ONNX格式，并在ONNX Runtime中加载和运行。
- **资源**：
  - [PyTorch官方文档 - 模型保存与加载](https://pytorch.org/docs/stable/notes/serialization.html)
  - [ONNX官方文档](https://onnx.ai/)

通过本文的学习，你应该已经掌握了PyTorch模型导出的基本方法，并能够在实际项目中应用这些知识。继续练习和探索，你将能够更熟练地处理模型导出与部署的相关任务。