---
title: PyTorch 模型保存与加载
description: 学习如何在PyTorch中保存和加载神经网络模型，以便在训练后重用或部署模型。
---

在深度学习中，训练一个神经网络模型可能需要大量的时间和计算资源。为了避免每次需要时重新训练模型，我们可以将训练好的模型保存到磁盘，并在需要时加载它。PyTorch 提供了简单而强大的工具来实现模型的保存与加载。本文将详细介绍如何在 PyTorch 中保存和加载模型，并通过实际案例帮助你理解这一过程。

## 1. 为什么需要保存和加载模型？

在训练深度学习模型时，模型的状态（包括权重、偏置等）会随着训练的进行而不断更新。保存模型的状态可以让我们在以下场景中受益：

- **模型重用**：保存训练好的模型，可以在未来的任务中直接加载并使用，而无需重新训练。
- **模型部署**：将模型保存后，可以将其部署到生产环境中，供应用程序调用。
- **训练中断恢复**：如果训练过程中断，可以从保存的检查点恢复训练，而不必从头开始。

## 2. 保存模型

在 PyTorch 中，保存模型的最简单方法是使用 `torch.save()` 函数。该函数可以将模型的状态字典（state_dict）保存到文件中。`state_dict` 是一个 Python 字典对象，它包含了模型的所有可学习参数（如权重和偏置）。

### 2.1 保存模型的 `state_dict`

以下是一个简单的示例，展示如何保存模型的 `state_dict`：

```python
import torch
import torch.nn as nn

# 定义一个简单的神经网络
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(10, 1)

    def forward(self, x):
        return self.fc(x)

# 实例化模型
model = SimpleModel()

# 保存模型的 state_dict
torch.save(model.state_dict(), 'model.pth')
```

在这个例子中，`model.state_dict()` 返回了模型的所有参数，`torch.save()` 将其保存到名为 `model.pth` 的文件中。

### 2.2 保存整个模型

除了保存 `state_dict`，你还可以保存整个模型。这种方法虽然简单，但不推荐在生产环境中使用，因为它依赖于特定的类和目录结构。

```python
# 保存整个模型
torch.save(model, 'model_entire.pth')
```

:::caution
保存整个模型可能会导致代码的可移植性降低，因为它依赖于模型定义时的环境。建议优先使用 `state_dict` 保存模型。
:::

## 3. 加载模型

加载模型的过程与保存模型的过程相对应。我们可以使用 `torch.load()` 函数加载保存的 `state_dict`，然后将其加载到模型中。

### 3.1 加载 `state_dict`

以下是如何加载 `state_dict` 的示例：

```python
# 实例化模型
model = SimpleModel()

# 加载 state_dict
model.load_state_dict(torch.load('model.pth'))

# 将模型设置为评估模式
model.eval()
```

在加载 `state_dict` 后，我们需要调用 `model.eval()` 将模型设置为评估模式。这是因为在训练和评估过程中，某些层（如 Dropout 和 BatchNorm）的行为是不同的。

### 3.2 加载整个模型

如果你保存了整个模型，可以使用以下方式加载：

```python
# 加载整个模型
model = torch.load('model_entire.pth')

# 将模型设置为评估模式
model.eval()
```

:::tip
在加载模型时，确保模型的定义与保存时的定义一致，否则可能会导致错误。
:::

## 4. 实际案例：保存和加载训练好的模型

假设我们正在训练一个简单的分类模型，并在每个 epoch 结束时保存模型的检查点。以下是一个完整的示例：

```python
import torch
import torch.nn as nn
import torch.optim as optim

# 定义一个简单的神经网络
class SimpleModel(nn.Module):
    def __init__(self):
        super(SimpleModel, self).__init__()
        self.fc = nn.Linear(10, 1)

    def forward(self, x):
        return self.fc(x)

# 实例化模型、损失函数和优化器
model = SimpleModel()
criterion = nn.MSELoss()
optimizer = optim.SGD(model.parameters(), lr=0.01)

# 模拟训练过程
for epoch in range(10):
    # 模拟输入数据
    inputs = torch.randn(10)
    targets = torch.randn(1)

    # 前向传播
    outputs = model(inputs)
    loss = criterion(outputs, targets)

    # 反向传播和优化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()

    # 每个 epoch 结束时保存模型
    torch.save(model.state_dict(), f'model_epoch_{epoch}.pth')
```

在训练完成后，我们可以加载任意一个 epoch 的检查点：

```python
# 加载第 5 个 epoch 的模型
model.load_state_dict(torch.load('model_epoch_5.pth'))
model.eval()
```

## 5. 总结

在本文中，我们学习了如何在 PyTorch 中保存和加载模型。我们介绍了保存模型的 `state_dict` 和整个模型的方法，并通过实际案例展示了如何在实际训练过程中使用这些技术。保存和加载模型是深度学习工作流中的重要步骤，它可以帮助我们重用模型、部署模型以及从训练中断中恢复。

## 6. 附加资源与练习

- **练习**：尝试在训练过程中保存模型的优化器状态，并在加载模型时恢复优化器状态。
- **进一步阅读**：查阅 PyTorch 官方文档，了解更多关于模型保存与加载的高级用法，如保存和加载多个模型、使用 `torch.jit` 进行模型序列化等。

通过掌握这些技能，你将能够更高效地管理和使用深度学习模型。祝你学习愉快！