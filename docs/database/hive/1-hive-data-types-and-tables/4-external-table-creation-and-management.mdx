---
title: 外部表创建与管理
description: 学习如何在 Hive 中创建和管理外部表，了解其与内部表的区别，并通过实际案例掌握其应用场景。
---

## 介绍

在 Hive 中，表可以分为**内部表（Managed Table）**和**外部表（External Table）**。外部表是 Hive 中一种特殊的表类型，它的数据存储位置由用户指定，而不是由 Hive 默认管理。这意味着，删除外部表时，Hive 只会删除表的元数据，而不会删除实际的数据文件。这使得外部表非常适合用于与其他系统共享数据，或者用于存储不希望被 Hive 自动删除的数据。

本文将详细介绍如何创建和管理外部表，并通过实际案例展示其应用场景。

---

## 外部表与内部表的区别

在深入外部表的创建与管理之前，我们需要先了解外部表与内部表的区别：

- **内部表**：数据由 Hive 管理，存储在 Hive 的默认仓库目录中。删除表时，Hive 会同时删除表的元数据和数据文件。
- **外部表**：数据由用户管理，存储在用户指定的位置。删除表时，Hive 只会删除表的元数据，而不会删除数据文件。

:::tip
如果你希望数据在删除表后仍然保留，或者数据需要与其他系统共享，外部表是一个更好的选择。
:::

---

## 创建外部表

在 Hive 中，创建外部表需要使用 `CREATE EXTERNAL TABLE` 语句，并通过 `LOCATION` 关键字指定数据存储的位置。

### 语法

```sql
CREATE EXTERNAL TABLE table_name (
  column1_name column1_type,
  column2_name column2_type,
  ...
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/path/to/data';
```

### 示例

假设我们有一个 CSV 文件 `employee_data.csv`，存储路径为 `/user/hive/employee_data`，文件内容如下：

```
1,John,Doe,50000
2,Jane,Smith,60000
3,Bob,Johnson,55000
```

我们可以通过以下语句创建一个外部表来管理这些数据：

```sql
CREATE EXTERNAL TABLE employee (
  id INT,
  first_name STRING,
  last_name STRING,
  salary INT
)
ROW FORMAT DELIMITED
FIELDS TERMINATED BY ','
STORED AS TEXTFILE
LOCATION '/user/hive/employee_data';
```

### 验证表创建

创建表后，可以通过以下命令查看表的结构：

```sql
DESCRIBE FORMATTED employee;
```

输出结果中，`Table Type` 字段会显示为 `EXTERNAL_TABLE`，同时 `Location` 字段会显示为 `/user/hive/employee_data`。

---

## 管理外部表

### 1. 查询外部表数据

外部表创建后，可以像普通表一样查询数据：

```sql
SELECT * FROM employee;
```

输出结果：

```
1   John    Doe     50000
2   Jane    Smith   60000
3   Bob     Johnson 55000
```

### 2. 删除外部表

删除外部表时，Hive 只会删除表的元数据，而不会删除数据文件：

```sql
DROP TABLE employee;
```

执行上述命令后，表 `employee` 的元数据会被删除，但 `/user/hive/employee_data` 目录下的数据文件仍然保留。

:::caution
删除外部表时，请确保你真的不需要这些数据，因为 Hive 不会自动删除它们。
:::

### 3. 修改外部表

如果需要修改外部表的结构或存储位置，可以使用 `ALTER TABLE` 语句。例如，添加一个新列：

```sql
ALTER TABLE employee ADD COLUMNS (department STRING);
```

---

## 实际案例：共享数据场景

假设你有一个团队，使用 Hive 进行数据分析，同时另一个团队使用 Spark 处理相同的数据。为了避免数据重复存储，你可以将数据存储在 HDFS 的共享目录中，并通过 Hive 和 Spark 分别创建外部表来访问这些数据。

### 步骤

1. 将数据文件上传到 HDFS 的共享目录，例如 `/shared/data/employee`。
2. 在 Hive 中创建外部表：

   ```sql
   CREATE EXTERNAL TABLE shared_employee (
     id INT,
     first_name STRING,
     last_name STRING,
     salary INT
   )
   ROW FORMAT DELIMITED
   FIELDS TERMINATED BY ','
   STORED AS TEXTFILE
   LOCATION '/shared/data/employee';
   ```

3. 在 Spark 中创建外部表（假设使用 Spark SQL）：

   ```scala
   val df = spark.read
     .option("header", "false")
     .option("inferSchema", "true")
     .csv("/shared/data/employee")
   df.createOrReplaceTempView("shared_employee")
   ```

通过这种方式，两个团队可以共享同一份数据，而无需重复存储。

---

## 总结

外部表是 Hive 中一种强大的工具，特别适合需要与其他系统共享数据或需要保留数据的场景。通过本文，你学习了如何创建和管理外部表，并通过实际案例了解了其应用场景。

:::note
记住，外部表的数据文件不会被 Hive 自动删除，因此在删除表时需要格外小心。
:::

---

## 附加资源与练习

### 练习

1. 创建一个外部表，数据文件存储在你本地的 HDFS 目录中。
2. 尝试删除该外部表，并验证数据文件是否仍然存在。
3. 修改外部表的结构，添加一个新列。

### 资源

- [Hive 官方文档](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL)
- [Hive 外部表与内部表的区别](https://www.tutorialspoint.com/hive/hive_internal_tables.htm)